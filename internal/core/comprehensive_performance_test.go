package core

import (
	"fmt"
	"testing"
	"time"

	"datax/internal/pkg/logger"
)

// TestComprehensivePerformanceOptimization ç»¼åˆæ€§èƒ½ä¼˜åŒ–æµ‹è¯•
func TestComprehensivePerformanceOptimization(t *testing.T) {
	// æ¨¡æ‹Ÿ500ä¸‡æ¡è®°å½•çš„æ€§èƒ½æµ‹è¯•
	totalRecords := int64(5000000)
	recordSize := 10
	logger := logger.New(nil)

	t.Logf("ğŸš€ å¼€å§‹ç»¼åˆæ€§èƒ½æµ‹è¯•")
	t.Logf("ç›®æ ‡: å¤„ç† %d æ¡è®°å½•ï¼Œä»åŸæ¥çš„5åˆ†é’Ÿä¼˜åŒ–åˆ°1åˆ†é’Ÿå†…", totalRecords)

	// ä½¿ç”¨ä¼˜åŒ–åçš„é…ç½®
	reader := &performanceReader{
		batchSize:    calculateBatchSize(totalRecords), // ä½¿ç”¨è‡ªé€‚åº”æ‰¹æ¬¡å¤§å°
		totalRecords: totalRecords,
		recordSize:   recordSize,
	}

	writer := &performanceWriter{}

	// ä½¿ç”¨æ‰€æœ‰ä¼˜åŒ–é…ç½®
	config := &PipelineConfig{
		BufferSize:       100,              // å¤§ç¼“å†²åŒº
		MaxRetries:       0,                // æ€§èƒ½æµ‹è¯•ä¸­ä¸é‡è¯•
		ProgressInterval: 10 * time.Second, // å‡å°‘è¿›åº¦è¾“å‡º
		WriterWorkers:    4,                // å¤šçº¿ç¨‹Writer
	}

	pipeline := NewPipeline(reader, writer, logger, config)

	// å¼€å§‹æ€§èƒ½æµ‹è¯•
	start := time.Now()
	err := pipeline.Start(totalRecords)
	elapsed := time.Since(start)

	if err != nil {
		t.Fatalf("Pipeline failed: %v", err)
	}

	stats := pipeline.GetStats()
	if stats.ProcessedRecords != totalRecords {
		t.Fatalf("Expected %d processed records, got %d", totalRecords, stats.ProcessedRecords)
	}

	// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
	recordsPerSecond := float64(totalRecords) / elapsed.Seconds()
	
	t.Logf("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
	t.Logf("  æ€»è®°å½•æ•°: %d", totalRecords)
	t.Logf("  æ€»è€—æ—¶: %v", elapsed)
	t.Logf("  å¤„ç†é€Ÿåº¦: %.2f æ¡/ç§’", recordsPerSecond)
	t.Logf("  æ‰¹æ¬¡å¤§å°: %d", reader.batchSize)
	t.Logf("  è¯»å–æ‰¹æ¬¡: %d", stats.ReadBatches)
	t.Logf("  å†™å…¥æ‰¹æ¬¡: %d", stats.WriteBatches)
	t.Logf("  Writerå·¥ä½œåç¨‹: %d", config.WriterWorkers)

	// æ€§èƒ½ç›®æ ‡éªŒè¯
	targetTime := 60 * time.Second // ç›®æ ‡1åˆ†é’Ÿå†…å®Œæˆ
	originalTime := 5 * time.Minute // åŸæ¥éœ€è¦5åˆ†é’Ÿ

	if elapsed <= targetTime {
		improvement := float64(originalTime) / float64(elapsed)
		t.Logf("âœ… æ€§èƒ½ç›®æ ‡è¾¾æˆï¼")
		t.Logf("  ç›®æ ‡æ—¶é—´: %v", targetTime)
		t.Logf("  å®é™…æ—¶é—´: %v", elapsed)
		t.Logf("  æ€§èƒ½æå‡: %.1fx", improvement)
	} else {
		improvement := float64(originalTime) / float64(elapsed)
		t.Logf("âš ï¸  æœªå®Œå…¨è¾¾åˆ°ç›®æ ‡æ—¶é—´ï¼Œä½†ä»æœ‰æ˜¾è‘—æå‡")
		t.Logf("  ç›®æ ‡æ—¶é—´: %v", targetTime)
		t.Logf("  å®é™…æ—¶é—´: %v", elapsed)
		t.Logf("  æ€§èƒ½æå‡: %.1fx", improvement)
	}

	// éªŒè¯æœ€ä½æ€§èƒ½è¦æ±‚ï¼šè‡³å°‘50,000æ¡/ç§’
	minRequiredSpeed := 50000.0
	if recordsPerSecond >= minRequiredSpeed {
		t.Logf("âœ… è¾¾åˆ°æœ€ä½æ€§èƒ½è¦æ±‚: %.2f æ¡/ç§’ >= %.0f æ¡/ç§’", recordsPerSecond, minRequiredSpeed)
	} else {
		t.Errorf("âŒ æœªè¾¾åˆ°æœ€ä½æ€§èƒ½è¦æ±‚: %.2f æ¡/ç§’ < %.0f æ¡/ç§’", recordsPerSecond, minRequiredSpeed)
	}
}

// TestOptimizationComparison ä¼˜åŒ–å‰åå¯¹æ¯”æµ‹è¯•
func TestOptimizationComparison(t *testing.T) {
	totalRecords := int64(1000000) // 100ä¸‡æ¡è®°å½•ç”¨äºå¿«é€Ÿå¯¹æ¯”
	recordSize := 10
	logger := logger.New(nil)

	t.Logf("ğŸ”„ ä¼˜åŒ–å‰åå¯¹æ¯”æµ‹è¯•")

	// æµ‹è¯•ä¼˜åŒ–å‰çš„é…ç½®ï¼ˆæ¨¡æ‹ŸåŸå§‹é…ç½®ï¼‰
	t.Run("ä¼˜åŒ–å‰", func(t *testing.T) {
		reader := &performanceReader{
			batchSize:    20000, // åŸå§‹è¾ƒå°çš„æ‰¹æ¬¡å¤§å°
			totalRecords: totalRecords,
			recordSize:   recordSize,
		}

		writer := &performanceWriter{}

		config := &PipelineConfig{
			BufferSize:       10,               // å°ç¼“å†²åŒº
			MaxRetries:       0,
			ProgressInterval: 500 * time.Millisecond, // é¢‘ç¹çš„è¿›åº¦æ›´æ–°
			WriterWorkers:    1, // å•çº¿ç¨‹Writer
		}

		pipeline := NewPipeline(reader, writer, logger, config)

		start := time.Now()
		err := pipeline.Start(totalRecords)
		elapsed := time.Since(start)

		if err != nil {
			t.Fatalf("Pipeline failed: %v", err)
		}

		recordsPerSecond := float64(totalRecords) / elapsed.Seconds()
		t.Logf("ä¼˜åŒ–å‰æ€§èƒ½:")
		t.Logf("  è€—æ—¶: %v", elapsed)
		t.Logf("  é€Ÿåº¦: %.2f æ¡/ç§’", recordsPerSecond)
		t.Logf("  æ‰¹æ¬¡å¤§å°: %d", reader.batchSize)
		t.Logf("  ç¼“å†²åŒºå¤§å°: %d", config.BufferSize)
		t.Logf("  Writeræ•°é‡: %d", config.WriterWorkers)
	})

	// æµ‹è¯•ä¼˜åŒ–åçš„é…ç½®
	t.Run("ä¼˜åŒ–å", func(t *testing.T) {
		reader := &performanceReader{
			batchSize:    calculateBatchSize(totalRecords), // è‡ªé€‚åº”æ‰¹æ¬¡å¤§å°
			totalRecords: totalRecords,
			recordSize:   recordSize,
		}

		writer := &performanceWriter{}

		config := &PipelineConfig{
			BufferSize:       100,              // å¤§ç¼“å†²åŒº
			MaxRetries:       0,
			ProgressInterval: 5 * time.Second, // å‡å°‘è¿›åº¦æ›´æ–°é¢‘ç‡
			WriterWorkers:    4, // å¤šçº¿ç¨‹Writer
		}

		pipeline := NewPipeline(reader, writer, logger, config)

		start := time.Now()
		err := pipeline.Start(totalRecords)
		elapsed := time.Since(start)

		if err != nil {
			t.Fatalf("Pipeline failed: %v", err)
		}

		recordsPerSecond := float64(totalRecords) / elapsed.Seconds()
		t.Logf("ä¼˜åŒ–åæ€§èƒ½:")
		t.Logf("  è€—æ—¶: %v", elapsed)
		t.Logf("  é€Ÿåº¦: %.2f æ¡/ç§’", recordsPerSecond)
		t.Logf("  æ‰¹æ¬¡å¤§å°: %d", reader.batchSize)
		t.Logf("  ç¼“å†²åŒºå¤§å°: %d", config.BufferSize)
		t.Logf("  Writeræ•°é‡: %d", config.WriterWorkers)
	})
}

// TestScalabilityAnalysis å¯æ‰©å±•æ€§åˆ†ææµ‹è¯•
func TestScalabilityAnalysis(t *testing.T) {
	logger := logger.New(nil)
	recordSize := 10

	dataSizes := []int64{
		100000,   // 10ä¸‡
		500000,   // 50ä¸‡
		1000000,  // 100ä¸‡
		2000000,  // 200ä¸‡
		5000000,  // 500ä¸‡
	}

	t.Logf("ğŸ“ˆ å¯æ‰©å±•æ€§åˆ†ææµ‹è¯•")

	for _, totalRecords := range dataSizes {
		t.Run(fmt.Sprintf("æ•°æ®é‡_%d", totalRecords), func(t *testing.T) {
			reader := &performanceReader{
				batchSize:    calculateBatchSize(totalRecords),
				totalRecords: totalRecords,
				recordSize:   recordSize,
			}

			writer := &performanceWriter{}

			config := &PipelineConfig{
				BufferSize:       100,
				MaxRetries:       0,
				ProgressInterval: 10 * time.Second,
				WriterWorkers:    4,
			}

			pipeline := NewPipeline(reader, writer, logger, config)

			start := time.Now()
			err := pipeline.Start(totalRecords)
			elapsed := time.Since(start)

			if err != nil {
				t.Fatalf("Pipeline failed: %v", err)
			}

			recordsPerSecond := float64(totalRecords) / elapsed.Seconds()
			
			t.Logf("æ•°æ®é‡ %d:", totalRecords)
			t.Logf("  è€—æ—¶: %v", elapsed)
			t.Logf("  é€Ÿåº¦: %.2f æ¡/ç§’", recordsPerSecond)
			t.Logf("  æ‰¹æ¬¡å¤§å°: %d", reader.batchSize)
			
			// éªŒè¯çº¿æ€§æ‰©å±•æ€§
			expectedMinSpeed := 30000.0 // æœ€ä½æœŸæœ›é€Ÿåº¦
			if recordsPerSecond < expectedMinSpeed {
				t.Errorf("æ€§èƒ½ä¸è¾¾æ ‡: %.2f æ¡/ç§’ < %.0f æ¡/ç§’", recordsPerSecond, expectedMinSpeed)
			}
		})
	}
}

// TestResourceUtilization èµ„æºåˆ©ç”¨ç‡æµ‹è¯•
func TestResourceUtilization(t *testing.T) {
	totalRecords := int64(1000000)
	recordSize := 10
	logger := logger.New(nil)

	// æµ‹è¯•ä¸åŒWriteræ•°é‡çš„æ€§èƒ½
	workerCounts := []int{1, 2, 4, 8}

	t.Logf("ğŸ”§ èµ„æºåˆ©ç”¨ç‡æµ‹è¯•")

	for _, workerCount := range workerCounts {
		t.Run(fmt.Sprintf("Workers_%d", workerCount), func(t *testing.T) {
			reader := &performanceReader{
				batchSize:    calculateBatchSize(totalRecords),
				totalRecords: totalRecords,
				recordSize:   recordSize,
			}

			writer := &performanceWriter{}

			config := &PipelineConfig{
				BufferSize:       100,
				MaxRetries:       0,
				ProgressInterval: 10 * time.Second,
				WriterWorkers:    workerCount,
			}

			pipeline := NewPipeline(reader, writer, logger, config)

			start := time.Now()
			err := pipeline.Start(totalRecords)
			elapsed := time.Since(start)

			if err != nil {
				t.Fatalf("Pipeline failed: %v", err)
			}

			recordsPerSecond := float64(totalRecords) / elapsed.Seconds()
			
			t.Logf("Workeræ•°é‡ %d:", workerCount)
			t.Logf("  è€—æ—¶: %v", elapsed)
			t.Logf("  é€Ÿåº¦: %.2f æ¡/ç§’", recordsPerSecond)
			t.Logf("  æ¯Workeræ•ˆç‡: %.2f æ¡/ç§’", recordsPerSecond/float64(workerCount))
		})
	}
}

// TestMemoryEfficiency å†…å­˜æ•ˆç‡æµ‹è¯•
func TestMemoryEfficiency(t *testing.T) {
	totalRecords := int64(1000000)
	recordSize := 20 // æ›´å¤§çš„è®°å½•å¤§å°
	logger := logger.New(nil)

	// æµ‹è¯•ä¸åŒç¼“å†²åŒºå¤§å°çš„å†…å­˜ä½¿ç”¨
	bufferSizes := []int{10, 50, 100, 200}

	t.Logf("ğŸ’¾ å†…å­˜æ•ˆç‡æµ‹è¯•")

	for _, bufferSize := range bufferSizes {
		t.Run(fmt.Sprintf("BufferSize_%d", bufferSize), func(t *testing.T) {
			reader := &performanceReader{
				batchSize:    calculateBatchSize(totalRecords),
				totalRecords: totalRecords,
				recordSize:   recordSize,
			}

			writer := &performanceWriter{}

			config := &PipelineConfig{
				BufferSize:       bufferSize,
				MaxRetries:       0,
				ProgressInterval: 10 * time.Second,
				WriterWorkers:    4,
			}

			pipeline := NewPipeline(reader, writer, logger, config)

			start := time.Now()
			err := pipeline.Start(totalRecords)
			elapsed := time.Since(start)

			if err != nil {
				t.Fatalf("Pipeline failed: %v", err)
			}

			recordsPerSecond := float64(totalRecords) / elapsed.Seconds()
			
			t.Logf("ç¼“å†²åŒºå¤§å° %d:", bufferSize)
			t.Logf("  è€—æ—¶: %v", elapsed)
			t.Logf("  é€Ÿåº¦: %.2f æ¡/ç§’", recordsPerSecond)
			
			// ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
			estimatedMemoryMB := float64(bufferSize * reader.batchSize * recordSize * 8) / 1024 / 1024
			t.Logf("  ä¼°ç®—å†…å­˜ä½¿ç”¨: %.2f MB", estimatedMemoryMB)
		})
	}
}
